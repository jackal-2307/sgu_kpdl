{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56a0e5de",
   "metadata": {},
   "source": [
    "**Bài toán 2: Tìm tập phổ biến cho bài toán đề xuất phim**. Dữ liệu lấy tại \n",
    "https://grouplens.org/datasets/movielens với MovieLens 100K dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8420df3b",
   "metadata": {},
   "source": [
    "**Nhiệm vụ 1:** Tìm tập phổ biến có trong tập dữ liệu phim "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150f1274",
   "metadata": {},
   "source": [
    "1. Import các gói thư viện, nạp dữ liệu và tiền xử lý dữ liệu vào notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bce4b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Favorable</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MovieID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Favorable\n",
       "MovieID           \n",
       "50             100\n",
       "100             89\n",
       "258             83\n",
       "181             79\n",
       "174             74"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "data_folder = \"Dataset/ml-100k\" \n",
    "ratings_filename = os.path.join(data_folder, \"u.data\") \n",
    "all_ratings = pd.read_csv(ratings_filename, delimiter=\"\\t\", header=None, \n",
    "  names = [\"UserID\", \"MovieID\", \"Rating\", \"Datetime\"]) \n",
    "all_ratings[\"Datetime\"] = pd.to_datetime(all_ratings['Datetime'],  \n",
    " unit='s') \n",
    "# Tạo cột mới tên Favorable \n",
    "all_ratings[\"Favorable\"] = all_ratings[\"Rating\"] > 3 \n",
    "ratings = all_ratings[all_ratings['UserID'].isin(range(200))] \n",
    "favorable_ratings = ratings[ratings[\"Favorable\"]] \n",
    "favorable_reviews_by_users = dict((k, frozenset(v.values)) for k, v in \n",
    "  favorable_ratings.groupby(\"UserID\")[\"MovieID\"]) \n",
    "num_favorable_by_movie = ratings[[\"MovieID\",  \n",
    " \"Favorable\"]].groupby(\"MovieID\").sum() \n",
    "num_favorable_by_movie.sort_values(by=\"Favorable\", \n",
    "ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfa7447",
   "metadata": {},
   "source": [
    "2.Tạo hàm để tìm tập phổ biến"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32ca5b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict \n",
    "def find_frequent_itemsets(favorable_reviews_by_users, k_1_itemsets, \n",
    "min_support): \n",
    "    counts = defaultdict(int) \n",
    "    for user, reviews in favorable_reviews_by_users.items(): \n",
    "        for itemset in k_1_itemsets: \n",
    "            if itemset.issubset(reviews): \n",
    "                for other_reviewed_movie in reviews - itemset: \n",
    "                    current_superset = itemset | frozenset((other_reviewed_movie,)) \n",
    "                    counts[current_superset] += 1 \n",
    "    return dict([(itemset, frequency) for itemset, frequency in \n",
    "                 counts.items() if frequency >= min_support]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c22e5a",
   "metadata": {},
   "source": [
    "3.Tìm tập phổ biến"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52b6ce06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 16 movies with more than 50 favorable reviews\n",
      "I found 93 frequent itemsets of length 2\n",
      "I found 295 frequent itemsets of length 3\n",
      "I found 593 frequent itemsets of length 4\n",
      "I found 785 frequent itemsets of length 5\n",
      "I found 677 frequent itemsets of length 6\n",
      "I found 373 frequent itemsets of length 7\n",
      "I found 126 frequent itemsets of length 8\n",
      "I found 24 frequent itemsets of length 9\n",
      "I found 2 frequent itemsets of length 10\n",
      "Did not find any frequent itemsets of length 11\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "frequent_itemsets = {}  # itemsets are sorted by length \n",
    "min_support = 50 \n",
    "# k=1 candidates are the isbns with more than min_support favourable reviews \n",
    "frequent_itemsets[1] = dict((frozenset((movie_id,)), row[\"Favorable\"]) \n",
    "            for movie_id, row in num_favorable_by_movie.iterrows() \n",
    "                if row[\"Favorable\"] > min_support) \n",
    "print(\"There are {} movies with more than {} favorable reviews\".format(len(frequent_itemsets[1]), min_support)) \n",
    "\n",
    "sys.stdout.flush() \n",
    "for k in range(2, 20): \n",
    "# Generate candidates of length k, using the frequent itemsets of length k-1 \n",
    "# Only store the frequent itemsets \n",
    "    cur_frequent_itemsets =  find_frequent_itemsets(favorable_reviews_by_users, \n",
    "                frequent_itemsets[k-1], min_support) \n",
    "    if len(cur_frequent_itemsets) == 0: \n",
    "        print(\"Did not find any frequent itemsets of length {}\".format(k)) \n",
    "        sys.stdout.flush() \n",
    "        break\n",
    "    else:    \n",
    "        print(\"I found {} frequent itemsets of length {}\".format(len(cur_frequent_itemsets), k)) \n",
    "        #print(cur_frequent_itemsets)\n",
    "        sys.stdout.flush()\n",
    "        frequent_itemsets[k] = cur_frequent_itemsets \n",
    "\n",
    "# We aren't interested in the itemsets of length 1, so remove those \n",
    "del frequent_itemsets[1] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
