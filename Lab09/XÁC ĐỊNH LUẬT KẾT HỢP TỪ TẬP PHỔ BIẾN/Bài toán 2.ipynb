{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ce4c30d",
   "metadata": {},
   "source": [
    "**Bài toán 2:** Tìm luật kết hợp trong tập dữ liệu phim. Dữ liệu lấy tại https://grouplens.org/datasets/movielens với MovieLens 100K dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b89f894",
   "metadata": {},
   "source": [
    "**Nhiệm vụ 1:** Tìm các luật kết hợp từ tập phổ biến"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a68253",
   "metadata": {},
   "source": [
    "### 1. Thực hiện các bước trong bài tập 1 để tìm tập phổ biến có trong dữ liệu đề xuất phim."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98f4501",
   "metadata": {},
   "source": [
    "1. Cài đặt các thư viện mlxtend và import các gói dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cd161965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Favorable</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MovieID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Favorable\n",
       "MovieID           \n",
       "50             100\n",
       "100             89\n",
       "258             83\n",
       "181             79\n",
       "174             74"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "data_folder = \"Data/ml-100k\" \n",
    "ratings_filename = os.path.join(data_folder, \"ml-100k\", \"u.data\") \n",
    "all_ratings = pd.read_csv(ratings_filename, delimiter=\"\\t\", header=None, \n",
    "  names = [\"UserID\", \"MovieID\", \"Rating\", \"Datetime\"]) \n",
    "all_ratings[\"Datetime\"] = pd.to_datetime(all_ratings['Datetime'],  unit='s') \n",
    "# Tạo cột mới tên Favorable \n",
    "all_ratings[\"Favorable\"] = all_ratings[\"Rating\"] > 3 \n",
    "ratings = all_ratings[all_ratings['UserID'].isin(range(200))] \n",
    "favorable_ratings = ratings[ratings[\"Favorable\"]] \n",
    "favorable_reviews_by_users = dict((k, frozenset(v.values)) for k, v in \n",
    "  favorable_ratings.groupby(\"UserID\")[\"MovieID\"]) \n",
    "num_favorable_by_movie = ratings[[\"MovieID\",  \n",
    " \"Favorable\"]].groupby(\"MovieID\").sum() \n",
    "num_favorable_by_movie.sort_values(by=\"Favorable\", \n",
    "ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1352549d",
   "metadata": {},
   "source": [
    "2. Tạo hàm để tìm tập phổ biến"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "07f16882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def find_frequent_itemsets(favorable_reviews_by_users, k_1_itemsets, min_support):\n",
    "    counts = defaultdict(int)\n",
    "\n",
    "    for user, reviews in favorable_reviews_by_users.items():\n",
    "        for itemset in k_1_itemsets:\n",
    "            if itemset.issubset(reviews):\n",
    "                for other_reviewed_movie in reviews - itemset:\n",
    "                    current_superset = itemset | frozenset((other_reviewed_movie,))\n",
    "                    counts[current_superset] += 1\n",
    "\n",
    "    return dict([\n",
    "        (itemset, frequency)\n",
    "        for itemset, frequency in counts.items()\n",
    "        if frequency >= min_support\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fc4ea0",
   "metadata": {},
   "source": [
    "3. Tìm tập phổ biến"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "82fde6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 16 movies with more than 50 favorable reviews\n",
      "I found 93 frequent itemsets of length 2\n",
      "I found 295 frequent itemsets of length 3\n",
      "I found 593 frequent itemsets of length 4\n",
      "I found 785 frequent itemsets of length 5\n",
      "I found 677 frequent itemsets of length 6\n",
      "I found 373 frequent itemsets of length 7\n",
      "I found 126 frequent itemsets of length 8\n",
      "I found 24 frequent itemsets of length 9\n",
      "I found 2 frequent itemsets of length 10\n",
      "Did not find any frequent itemsets of length 11\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "frequent_itemsets = {}  # itemsets are sorted by length\n",
    "min_support = 50\n",
    "\n",
    "# k=1 candidates are the movies with more than min_support favourable reviews\n",
    "frequent_itemsets[1] = dict(\n",
    "    (frozenset((movie_id,)), row[\"Favorable\"])\n",
    "    for movie_id, row in num_favorable_by_movie.iterrows()\n",
    "    if row[\"Favorable\"] > min_support\n",
    ")\n",
    "\n",
    "print(\"There are {} movies with more than {} favorable reviews\"\n",
    "      .format(len(frequent_itemsets[1]), min_support))\n",
    "\n",
    "sys.stdout.flush()\n",
    "\n",
    "for k in range(2, 20):\n",
    "    # Generate candidates of length k, using the frequent itemsets of length k-1\n",
    "    # Only store the frequent itemsets\n",
    "    cur_frequent_itemsets = find_frequent_itemsets(\n",
    "        favorable_reviews_by_users,\n",
    "        frequent_itemsets[k-1],\n",
    "        min_support\n",
    "    )\n",
    "\n",
    "    if len(cur_frequent_itemsets) == 0:\n",
    "        print(\"Did not find any frequent itemsets of length {}\".format(k))\n",
    "        sys.stdout.flush()\n",
    "        break\n",
    "    else:\n",
    "        print(\"I found {} frequent itemsets of length {}\"\n",
    "              .format(len(cur_frequent_itemsets), k))\n",
    "        #print(cur_frequent_itemsets)\n",
    "        sys.stdout.flush()\n",
    "        frequent_itemsets[k] = cur_frequent_itemsets\n",
    "\n",
    "# We aren't interested in the itemsets of length 1, so remove those\n",
    "del frequent_itemsets[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dbcad7",
   "metadata": {},
   "source": [
    "### 2. Xác định danh sách các tập luật ứng tuyển"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6d8e424b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 15285 candidate rules\n"
     ]
    }
   ],
   "source": [
    "# Now we create the association rules. First, they are candidates until the confidence has been tested \n",
    "candidate_rules = [] \n",
    "for itemset_length, itemset_counts in frequent_itemsets.items(): \n",
    "   for itemset in itemset_counts.keys(): \n",
    "      for conclusion in itemset: \n",
    "         premise = itemset - set((conclusion,)) \n",
    "         candidate_rules.append((premise, conclusion)) \n",
    "# There are 15285 candidate rules \n",
    "print(\"There are {} candidate rules\".format(len(candidate_rules)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491d675e",
   "metadata": {},
   "source": [
    "### 3. Tính mức độ tin cậy (confidence) từng luật ứng tuyển"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "37238c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we compute the confidence of each of these rules. This is very similar to what we did in chapter 1 \n",
    "correct_counts = defaultdict(int) \n",
    "incorrect_counts = defaultdict(int) \n",
    "for user, reviews in favorable_reviews_by_users.items(): \n",
    "    for candidate_rule in candidate_rules: \n",
    "        premise, conclusion = candidate_rule \n",
    "        if premise.issubset(reviews): \n",
    "            if conclusion in reviews: \n",
    "                correct_counts[candidate_rule] += 1 \n",
    "            else:\n",
    "                incorrect_counts[candidate_rule] += 1 \n",
    "rule_confidence = {candidate_rule: correct_counts[candidate_rule] / \n",
    "float(correct_counts[candidate_rule] + incorrect_counts[candidate_rule]) \n",
    "    for candidate_rule in candidate_rules}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d767313",
   "metadata": {},
   "source": [
    "### 4. Lấy các luật có độ tin cậy > 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "862ed91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5152\n"
     ]
    }
   ],
   "source": [
    "min_confidence = 0.9 \n",
    "# Filter out the rules with poor confidence \n",
    "rule_confidence = {rule: confidence for rule, confidence in \n",
    "    rule_confidence.items() if confidence > min_confidence} \n",
    "print(len(rule_confidence)) #5152 luật"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b61d6ef",
   "metadata": {},
   "source": [
    "### 5. Liệt kê năm luật kết hợp có độ tin cậy cao nhất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "40dad8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule #1:\n",
      "Rule: If a person recommends frozenset({np.int64(98), np.int64(181)}) they will also recommend 50\n",
      "-- Confidence: 1.000\n",
      "\n",
      "Rule #2:\n",
      "Rule: If a person recommends frozenset({np.int64(172), 79}) they will also recommend 174\n",
      "-- Confidence: 1.000\n",
      "\n",
      "Rule #3:\n",
      "Rule: If a person recommends frozenset({np.int64(258), 172}) they will also recommend 174\n",
      "-- Confidence: 1.000\n",
      "\n",
      "Rule #4:\n",
      "Rule: If a person recommends frozenset({1, np.int64(181), np.int64(7)}) they will also recommend 50\n",
      "-- Confidence: 1.000\n",
      "\n",
      "Rule #5:\n",
      "Rule: If a person recommends frozenset({1, np.int64(172), np.int64(7)}) they will also recommend 174\n",
      "-- Confidence: 1.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "sorted_confidence = sorted(\n",
    "    rule_confidence.items(),\n",
    "    key=itemgetter(1),\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "for index in range(min(5, len(sorted_confidence))):\n",
    "    # lấy premise và conclusion\n",
    "    (premise, conclusion) = sorted_confidence[index][0]\n",
    "\n",
    "    print(\"Rule #{0}:\".format(index + 1))\n",
    "    print(\"Rule: If a person recommends {0} they will also recommend {1}\"\n",
    "          .format(premise, conclusion))\n",
    "    print(\"-- Confidence: {0:.3f}\"\n",
    "          .format(rule_confidence[(premise, conclusion)]))\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fee8936",
   "metadata": {},
   "source": [
    "### 6. Hiển thị tên phim cụ thể trong các luật kết hợp đã tìm thấy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ba8881de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule #1\n",
      "Rule: If a person recommends Silence of the Lambs, The (1991), Return of the Jedi (1983) they will also recommend Star Wars (1977)\n",
      " - Confidence: 1.000\n",
      "\n",
      "Rule #2\n",
      "Rule: If a person recommends Empire Strikes Back, The (1980), Fugitive, The (1993) they will also recommend Raiders of the Lost Ark (1981)\n",
      " - Confidence: 1.000\n",
      "\n",
      "Rule #3\n",
      "Rule: If a person recommends Contact (1997), Empire Strikes Back, The (1980) they will also recommend Raiders of the Lost Ark (1981)\n",
      " - Confidence: 1.000\n",
      "\n",
      "Rule #4\n",
      "Rule: If a person recommends Toy Story (1995), Return of the Jedi (1983), Twelve Monkeys (1995) they will also recommend Star Wars (1977)\n",
      " - Confidence: 1.000\n",
      "\n",
      "Rule #5\n",
      "Rule: If a person recommends Toy Story (1995), Empire Strikes Back, The (1980), Twelve Monkeys (1995) they will also recommend Raiders of the Lost Ark (1981)\n",
      " - Confidence: 1.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we can get the movie titles themselves from the dataset \n",
    "movie_name_filename = os.path.join(data_folder, \"ml-100k\", \"u.item\") \n",
    "movie_name_data = pd.read_csv(movie_name_filename, delimiter=\"|\", header=None, encoding = \"mac-roman\")\n",
    "movie_name_data.columns = [\"MovieID\", \"Title\", \"Release Date\", \"Video Release\", \"IMDB\", \"<UNK>\", \"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\", \"Crime\",  \n",
    " \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \n",
    " \"Horror\", \"Musical\", \"Mystery\", \"Romance\",  \n",
    " \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"] \n",
    "def get_movie_name(movie_id): \n",
    " title_object = movie_name_data[movie_name_data[\"MovieID\"] == movie_id][\"Title\"] \n",
    " title = title_object.values[0] \n",
    " return title \n",
    "for index in range(min(5, len(sorted_confidence))): \n",
    " print(\"Rule #{0}\".format(index + 1)) \n",
    " (premise, conclusion) = sorted_confidence[index][0] \n",
    " premise_names = \", \".join(get_movie_name(idx) for idx in premise) \n",
    " conclusion_name = get_movie_name(conclusion) \n",
    " print(\"Rule: If a person recommends {0} they will also recommend {1}\".format(premise_names, conclusion_name)) \n",
    " print(\" - Confidence: {0:.3f}\".format(rule_confidence[(premise, conclusion)])) \n",
    " print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
